{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"count app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text file\n",
    "text_file = sc.textFile(\"data/divine_comedy.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/e:/Clases Aspacia/ds-aspacia/data/divine_comedy.txt\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:304)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:244)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:332)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:208)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:292)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:292)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:288)\r\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:292)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:288)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.IOException: Input path does not exist: file:/e:/Clases Aspacia/ds-aspacia/data/divine_comedy.txt\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:278)\r\n\t... 34 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate the total number of words\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=1'>2</a>\u001b[0m num_words \u001b[39m=\u001b[39m text_file\u001b[39m.\u001b[39;49mflatMap(\u001b[39mlambda\u001b[39;49;00m line: line\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49mcount()\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe file has \u001b[39m\u001b[39m{\u001b[39;00mnum_words\u001b[39m}\u001b[39;00m\u001b[39m words.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W6sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39m# Use the count action to get the number of lines\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\rdd.py:1521\u001b[0m, in \u001b[0;36mRDD.count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m   1513\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \u001b[39m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[0;32m   1515\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[39m    3\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1521\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapPartitions(\u001b[39mlambda\u001b[39;49;00m i: [\u001b[39msum\u001b[39;49m(\u001b[39m1\u001b[39;49m \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m i)])\u001b[39m.\u001b[39;49msum()\n",
      "File \u001b[1;32mc:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\rdd.py:1508\u001b[0m, in \u001b[0;36mRDD.sum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mRDD[NumberOrArray]\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNumberOrArray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1500\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m \u001b[39m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m \u001b[39m    6.0\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1508\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapPartitions(\u001b[39mlambda\u001b[39;49;00m x: [\u001b[39msum\u001b[39;49m(x)])\u001b[39m.\u001b[39;49mfold(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   1509\u001b[0m         \u001b[39m0\u001b[39;49m, operator\u001b[39m.\u001b[39;49madd\n\u001b[0;32m   1510\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\rdd.py:1336\u001b[0m, in \u001b[0;36mRDD.fold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[39myield\u001b[39;00m acc\n\u001b[0;32m   1333\u001b[0m \u001b[39m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[0;32m   1334\u001b[0m \u001b[39m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[39m# to the final reduce call\u001b[39;00m\n\u001b[1;32m-> 1336\u001b[0m vals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapPartitions(func)\u001b[39m.\u001b[39;49mcollect()\n\u001b[0;32m   1337\u001b[0m \u001b[39mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[1;32mc:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\rdd.py:1197\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext):\n\u001b[0;32m   1196\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mctx\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1197\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonRDD\u001b[39m.\u001b[39;49mcollectAndServe(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jrdd\u001b[39m.\u001b[39;49mrdd())\n\u001b[0;32m   1198\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[1;32mc:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\Users\\Rodrigo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/e:/Clases Aspacia/ds-aspacia/data/divine_comedy.txt\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:304)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:244)\r\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:332)\r\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:208)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:292)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:288)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:292)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:288)\r\n\tat org.apache.spark.api.python.PythonRDD.getPartitions(PythonRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$partitions$2(RDD.scala:292)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:288)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.IOException: Input path does not exist: file:/e:/Clases Aspacia/ds-aspacia/data/divine_comedy.txt\r\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:278)\r\n\t... 34 more\r\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of words\n",
    "num_words = text_file.flatMap(lambda line: line.split(\" \")).count()\n",
    "print(f\"The file has {num_words} words.\")\n",
    "# Use the count action to get the number of lines\n",
    "num_lines = text_file.count()\n",
    "\n",
    "print(f\"The file has {num_lines} lines.\")\n",
    "# Calculate the average number of words per line\n",
    "\n",
    "avg_words_per_line = num_words / num_lines\n",
    "\n",
    "print(f\"The average number of words per line is {avg_words_per_line}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlatMap transformation to split the lines into words\n",
    "words = text_file.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Map transformation to create a pair for each word,\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# and ReduceByKey transformation to count the occurrences\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m word_counts \u001b[39m=\u001b[39m words\u001b[39m.\u001b[39mmap(\n\u001b[0;32m      4\u001b[0m     \u001b[39mlambda\u001b[39;00m word: (word, \u001b[39m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m )\u001b[39m.\u001b[39mreduceByKey(\u001b[39mlambda\u001b[39;00m a,b:a \u001b[39m+\u001b[39mb)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "# Map transformation to create a pair for each word,\n",
    "# and ReduceByKey transformation to count the occurrences\n",
    "word_counts = words.map(\n",
    "    lambda word: (word, 1)\n",
    ").reduceByKey(lambda a,b:a +b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect action to bring the data back to the driver program as a list\n",
    "output = word_counts.collect()\n",
    "\n",
    "for (word, count) in output:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the takeOrdered action to get the 10 most common words\n",
    "top10 = word_counts.takeOrdered(10, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the words and counts into two lists\n",
    "words = [i[0] for i in top10]\n",
    "counts = [i[1] for i in top10]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(words, counts, color ='maroon', width = 0.6)\n",
    "\n",
    "plt.xlabel(\"Words\") \n",
    "plt.ylabel(\"Counts\") \n",
    "plt.title(\"Top 10 most common words\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
